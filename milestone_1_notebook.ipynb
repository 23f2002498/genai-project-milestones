{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 128431,
          "databundleVersionId": 15477148,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31259,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/23f2002498/genai-project-milestones/blob/main/milestone_1_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Milestone 1\n",
        "\n",
        "This milestone focuses on understanding the dataset and establishing a baseline performance through **exploratory data analysis (EDA)** and simple **heuristic-based methods** using `librosa`.\n",
        "\n",
        "---\n",
        "\n",
        "## Suggested Readings\n",
        "- [Hugging Face Audio Course](https://huggingface.co/learn/audio-course/en/chapter0/introduction)\n",
        "- [Librosa Documentation](https://librosa.org/doc/main/core.html#audio-loading)\n",
        "\n",
        "---\n",
        "\n",
        "## Instructions\n",
        "Use this notebook to answer **all Milestone-1 questions**.\n",
        "\n",
        "---\n",
        "\n",
        "## Resources\n",
        "- Notebook Link:  \n",
        "  https://colab.research.google.com/drive/1m6UczhxQIke_raWSqukSWuiKbIVt7MMb?usp=sharing  \n",
        "\n",
        "- Competition Link:  \n",
        "  https://www.kaggle.com/competitions/jan-2026-dl-gen-ai-project/\n"
      ],
      "metadata": {
        "id": "2OhS0NNSgfjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import torch\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "P98avCy_pVzP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#----------------------------- DON'T CHANGE THIS --------------------------\n",
        "DATA_SEED = 67\n",
        "TRAINING_SEED = 1234\n",
        "SR = 22050\n",
        "DURATION = 5.0\n",
        "N_FFT = 2048\n",
        "HOP_LENGTH = 512\n",
        "N_MELS = 128\n",
        "TOP_DB=20\n",
        "TARGET_SNR_DB = 10\n",
        "\n",
        "random.seed(DATA_SEED)\n",
        "np.random.seed(DATA_SEED)\n",
        "torch.manual_seed(DATA_SEED)\n",
        "torch.cuda.manual_seed(DATA_SEED)"
      ],
      "metadata": {
        "trusted": true,
        "id": "FJDKs-0cpVzR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFIGURATION\n",
        "DATA_ROOT = # Enter dataset path\n",
        "GENRES = [] # Make the list of all genres available (alphabetical order)\n",
        "STEMS = {} # Write here stems file name\n",
        "STEM_KEYS = ['drums', 'vocals', 'bass', 'other']\n",
        "GENRE_TO_TEST = 'rock'\n",
        "SONG_INDEX = #Enter index as per Q10."
      ],
      "metadata": {
        "trusted": true,
        "id": "3bcdenPtpVzS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset(root_dir, val_split=0.17, seed=42):\n",
        "    # Initialize empty dictionaries\n",
        "    train_dataset = {g: {s.replace('.wav', ''): [] for s in STEMS} for g in GENRES}\n",
        "    val_dataset   = {g: {s.replace('.wav', ''): [] for s in STEMS} for g in GENRES}\n",
        "\n",
        "    rng = random.Random(seed)\n",
        "\n",
        "    # ------------------- write your code here -------------------------------\n",
        "\n",
        "        # Iterate through Genres\n",
        "        # Check: if genre folder exists\n",
        "        # CHECK : Completeness (Does it have all stems?)\n",
        "        # CHECK : Corruption (Is any file too small? (less than 4kb))\n",
        "        # size checks\n",
        "        # Stratified Shuffle Split\n",
        "     #-------------------------------------------------------------------------\n",
        "\n",
        "        # Helper function to populate dict\n",
        "        def add_to_dict(target_dict, song_list):\n",
        "            pass\n",
        "\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "tr, val = build_dataset(DATA_ROOT)"
      ],
      "metadata": {
        "trusted": true,
        "id": "SD382v9NpVzS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def find_long_silences(dataset_dict, sr=SR, threshold_sec=DURATION, top_db=TOP_DB):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        dataset_dict: The dictionary structure {genre: {stem: [paths...]}}\n",
        "    Output:\n",
        "        df: Pandas DataFrame containing details of all files with silence >= 5s\n",
        "    \"\"\"\n",
        "    records = []\n",
        "    # ------------------- write your code here -------------------------------\n",
        "\n",
        "    total_files =     # ---- COUNT TOTAL FILES ----\n",
        "\n",
        "\n",
        "\n",
        "        # Load Audio\n",
        "\n",
        "        # Find Non-Silent Intervals\n",
        "\n",
        "        # CASE A: Fully silent\n",
        "        # CASE B: START silence\n",
        "        # CASE C: END silence\n",
        "        # CASE D: MIDDLE silence\n",
        "\n",
        "        # Store result\n",
        "        # if max_silence >= threshold_sec:\n",
        "        #     records.append({\n",
        "        #         \"Genre\": genre,\n",
        "        #         \"Stem\": stem_name,\n",
        "        #         \"Duration\": round(total_duration, 2),\n",
        "        #         \"Max_Silence_Sec\": round(max_silence, 2),\n",
        "        #         \"Silence_Location\": \", \".join(silence_type),\n",
        "        #         \"File_Path\": file_path\n",
        "        #     })\n",
        "    #-------------------------------------------------------------------------\n",
        "    df = pd.DataFrame(records)\n",
        "    return df\n",
        "\n",
        "\n",
        "# --- EXECUTION ---\n",
        "# Pass your 'tr' (training) dictionary here.\n",
        "# Ensure 'tr' is defined from your previous build_dataset code.\n",
        "df_silence = find_long_silences(tr, threshold_sec=DURATION, top_db=TOP_DB)\n",
        "\n",
        "# --- RESULTS ANALYSIS ---\n",
        "\n",
        "# ------------------- write your code here -------------------------------\n",
        "#-------------------------------------------------------------------------\n",
        "# Hint: Create a pivot Table: Count by Genre vs Stem\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "QEDE0cXmpVzS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "stems_audio = []\n",
        "try:\n",
        "    for key in STEM_KEYS:\n",
        "      pass\n",
        "    # ------------------- write your code here -------------------------------\n",
        "    # Load audio (Duration 5.0s for speed/consistency)\n",
        "    #-------------------------------------------------------------------------\n",
        "\n",
        "    print(\"Audio loaded successfully.\")\n",
        "except NameError:\n",
        "    print(\"ERROR: 'tr' dictionary not found. Please run build_dataset() first.\")\n",
        "except IndexError:\n",
        "    print(f\"ERROR: Song index {SONG_INDEX} out of range for genre {GENRE_TO_TEST}.\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: {e}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "yQ5TsIJupVzT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------- write your code here -------------------------------\n",
        "# Stack them into a numpy array (Shape: 4 x Samples)\n",
        "stems_stack =\n",
        "\n",
        "# Mix the stems by summing them element-wise\n",
        "mix_raw =\n",
        "\n",
        "# Calculate RMS Amplitude MANUALLY\n",
        "rms_val =\n",
        "\n",
        "#Peak Normalization\n",
        "max_val =\n",
        "\n",
        "if max_val > 0:\n",
        "    mix_norm = mix_raw / max_val\n",
        "else:\n",
        "    mix_norm = mix_raw\n",
        "\n",
        "# VALIDATION\n",
        "assert np.isclose(np.max(np.abs(mix_norm)), 1.0), \"Normalization failed.\"\n",
        "#------------------------------------------------------------------------\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "7SuonlR-pVzT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "Zgfv9CEZpVzT"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}